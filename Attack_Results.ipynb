{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN4NzcYE8VQ0"
      },
      "source": [
        "# The Results of the Baseline and Adversarially Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tth3s7W98Nzj"
      },
      "source": [
        "The code block provided is designed to validate the training process by loading the model weights of epoch 10. This validation applies to both the baseline model, which has been trained on standard data, and the model that has been specifically trained using adversarial examples. To assess the models' performance, we will conduct tests using benign test cases. For this evaluation, we will randomly select 150 samples from the benign dataset. This sample size is chosen to match the number of adversarial examples used in previous testing, ensuring a balanced comparison between the two types of models. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJz33Grjh_U0",
        "outputId": "4c2b1a2d-c52f-4a73-9c53-ddfaac1d4761"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from collections import namedtuple\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import hashlib\n",
        "import json\n",
        "import random\n",
        "\n",
        "random.seed(42) # Setting seed\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "codebert_model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "\n",
        "batch_size = 8\n",
        "num_epochs = 10\n",
        "learning_rate = 1e-5\n",
        "weight_decay = 0.05\n",
        "class_weights = torch.tensor([1.9, 0.68])\n",
        "\n",
        "# Create the classification head\n",
        "class CodeBERTForVulnDetection(nn.Module):\n",
        "  def __init__(self, codebert):\n",
        "    super(CodeBERTForVulnDetection, self).__init__()\n",
        "\n",
        "    self.codebert = codebert\n",
        "    self.dropout1 = nn.Dropout(p=0.2)\n",
        "    self.linear1 = nn.Linear(768, 3072)\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.dropout2 = nn.Dropout(p=0.2)\n",
        "    self.linear2 = nn.Linear(3072, 3072)\n",
        "    self.classifier = nn.Linear(3072, 2)\n",
        "\n",
        "    self.loss_func = nn.BCEWithLogitsLoss(weight=class_weights)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    # codeBERT output pooled\n",
        "    output = self.codebert(input_ids = input_ids, attention_mask = attention_mask)\n",
        "    output = torch.mean(output.last_hidden_state, 1)\n",
        "\n",
        "    # classification head (https://arxiv.org/pdf/2204.03214.pdf, Table 4)\n",
        "    output = self.dropout1(output)\n",
        "    output = self.linear1(output)\n",
        "    output = self.tanh(output)\n",
        "    output = self.dropout2(output)\n",
        "    output = self.linear2(output)\n",
        "    output = self.classifier(output)\n",
        "\n",
        "    return output\n",
        "\n",
        "# remove duplicates and conflicting labels\n",
        "def clean_data(text_samples, labels):\n",
        "  hashmap = {}\n",
        "  blacklist = []\n",
        "\n",
        "  for i in range(len(text_samples)):\n",
        "    sample_digest = hashlib.sha256(text_samples[i].encode('utf-8')).hexdigest()\n",
        "\n",
        "    if hashmap.get(sample_digest) == None:\n",
        "      hashmap[sample_digest] = (labels[i], i)\n",
        "    else:\n",
        "      if hashmap[sample_digest][0] != labels[i] and (sample_digest not in blacklist):\n",
        "        blacklist.append(sample_digest)\n",
        "\n",
        "  for blacklisted_sample in blacklist:\n",
        "    hashmap.pop(blacklisted_sample)\n",
        "\n",
        "  values = hashmap.values()\n",
        "\n",
        "  cleaned_samples = [text_samples[val[1]] for val in values]\n",
        "  cleaned_labels = [labels[val[1]] for val in values]\n",
        "\n",
        "  return cleaned_samples, cleaned_labels\n",
        "\n",
        "class VulDeePeckerDataset(Dataset):\n",
        "  def __init__(self, samples, labels, tokenizer):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.samples = samples\n",
        "    self.labels = labels\n",
        "\n",
        "    # Clean Data\n",
        "    self.samples, self.labels = clean_data(self.samples, self.labels)\n",
        "\n",
        "    # Tokenize samples\n",
        "    self.samples = self.tokenizer(self.samples, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    label = torch.tensor([self.labels[idx], 1 - self.labels[idx]], dtype=torch.float32)\n",
        "    return self.samples[\"input_ids\"][idx].squeeze(), self.samples[\"attention_mask\"][idx].squeeze(), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tH1pNMKIigSy"
      },
      "outputs": [],
      "source": [
        "def testing(checkpoint_path, adv_testing):\n",
        "  # Import the dataset\n",
        "  print(\"Loading dataset...\")\n",
        "  samples = []\n",
        "  labels = []\n",
        "\n",
        "  if adv_testing:\n",
        "    json_directory = \"ADV_data\" # Directory containing the adversarial data\n",
        "\n",
        "    for filename in os.listdir(json_directory):\n",
        "        if filename.endswith(\".json\"): \n",
        "            file_path = os.path.join(json_directory, filename)\n",
        "            with open(file_path, \"r\") as f:\n",
        "                for line in f:\n",
        "                    json_object = json.loads(line)\n",
        "                    samples.append(json_object['func'])\n",
        "                    labels.append(json_object['target'])\n",
        "  else:\n",
        "    # Directory containing the benign data\n",
        "    json_directory = \"test_data\"\n",
        "\n",
        "    for filename in os.listdir(json_directory):\n",
        "        if filename.endswith(\".json\"):  \n",
        "            file_path = os.path.join(json_directory, filename)\n",
        "            with open(file_path, \"r\") as f:\n",
        "                for line in f:\n",
        "                    json_object = json.loads(line)\n",
        "                    samples.append(json_object['func'])\n",
        "                    labels.append(json_object['target'])\n",
        "\n",
        "    num_indices = 150\n",
        "    random_indices = random.sample(range(len(samples)), num_indices)\n",
        "\n",
        "    # Get the corresponding samples using the random indices to match the number of adversarial samples\n",
        "    samples = [samples[i] for i in random_indices]\n",
        "    labels = [labels[i] for i in random_indices]\n",
        "\n",
        "  # Load model architecture\n",
        "  model = CodeBERTForVulnDetection(codebert_model)\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = model.to(device)\n",
        "\n",
        "  # Load the test dataset\n",
        "  test_dataset = VulDeePeckerDataset(samples, labels, tokenizer)\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  # Define evaluation function\n",
        "  # Evaluate model\n",
        "  def evaluate(dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for input_ids, attention_mask, labels in dataloader:\n",
        "          # transfer to GPU if available\n",
        "          input_ids = input_ids.to(device)\n",
        "          attention_mask = attention_mask.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # forward pass\n",
        "          outputs = model.forward(input_ids, attention_mask)\n",
        "\n",
        "          # find predictions and truths to calculate confusion matrix\n",
        "          all_labels += torch.min(labels.cpu(), dim=1).indices.tolist()\n",
        "          all_predictions += torch.min(outputs.cpu(), dim=1).indices.tolist()\n",
        "\n",
        "    # evaluation scores\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision = precision_score(all_labels, all_predictions)\n",
        "    recall = recall_score(all_labels, all_predictions)\n",
        "    f1 = f1_score(all_labels, all_predictions)\n",
        "\n",
        "    # Calculate false positive rate (FPR) and false negative rate (FNR)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    fpr = fp / (fp + tn)\n",
        "    fnr = fn / (fn + tp)\n",
        "\n",
        "    # Create a named tuple to return values\n",
        "    RetType = namedtuple(\"RetType\", [\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"fpr\", \"fnr\"])\n",
        "\n",
        "    return RetType(accuracy, precision, recall, f1, fpr, fnr)\n",
        "\n",
        "  # Load checkpoint\n",
        "  model.load_state_dict(torch.load(checkpoint_path))\n",
        "  model.to(device)\n",
        "\n",
        "  # Run evaluation\n",
        "  eval_result = evaluate(test_dataloader)\n",
        "  print(\"\\rEpoch {} performance metrics:\\nAccuracy: {:.4f}\\nPrecision: {:.4f}\\nRecall: {:.4f}\\nF1 Score: {:.4f}\\nFalse Positive Rate: {:.4f}\\nFalse Negative Rate: {:.4f}\".format(\n",
        "          10,\n",
        "          eval_result.accuracy,\n",
        "          eval_result.precision,\n",
        "          eval_result.recall,\n",
        "          eval_result.f1_score,\n",
        "          eval_result.fpr,\n",
        "          eval_result.fnr\n",
        "      ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C2b24S_k2Tb"
      },
      "source": [
        "Conduct tests on the benign model using two distinct sets of test cases: the benign test cases and the adversarial test cases. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vSnFgefjBCu",
        "outputId": "eaf8c61b-66c2-4f41-89f3-46992c22a2c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-747bdb743540>:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rEpoch 10 performance metrics:\n",
            "Accuracy: 0.9133\n",
            "Precision: 0.9302\n",
            "Recall: 0.8000\n",
            "F1 Score: 0.8602\n",
            "False Positive Rate: 0.0300\n",
            "False Negative Rate: 0.2000\n",
            "---------------------------------------------------\n",
            "Loading dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-747bdb743540>:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path))\n",
            "<ipython-input-2-747bdb743540>:83: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  fpr = fp / (fp + tn)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rEpoch 10 performance metrics:\n",
            "Accuracy: 0.2671\n",
            "Precision: 1.0000\n",
            "Recall: 0.2671\n",
            "F1 Score: 0.4216\n",
            "False Positive Rate: nan\n",
            "False Negative Rate: 0.7329\n"
          ]
        }
      ],
      "source": [
        "testing('epoch10_checkpoint.ckpt', False)\n",
        "print(\"---------------------------------------------------\")\n",
        "testing('epoch10_checkpoint.ckpt', True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChWRGcrwlBND"
      },
      "source": [
        "Conduct tests on the adversarially trained model using two sets of test cases: the benign test cases and the adversarial test cases. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Xh3fcVOjkHc",
        "outputId": "c0dc4ece-a003-4d94-eba1-19c0141edfdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-747bdb743540>:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rEpoch 10 performance metrics:\n",
            "Accuracy: 0.9067\n",
            "Precision: 0.9130\n",
            "Recall: 0.8077\n",
            "F1 Score: 0.8571\n",
            "False Positive Rate: 0.0408\n",
            "False Negative Rate: 0.1923\n",
            "---------------------------------------------------\n",
            "Loading dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-747bdb743540>:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rEpoch 10 performance metrics:\n",
            "Accuracy: 0.5960\n",
            "Precision: 1.0000\n",
            "Recall: 0.5960\n",
            "F1 Score: 0.7469\n",
            "False Positive Rate: nan\n",
            "False Negative Rate: 0.4040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-747bdb743540>:83: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  fpr = fp / (fp + tn)\n"
          ]
        }
      ],
      "source": [
        "testing('epoch10_checkpoint_adv.ckpt', False)\n",
        "print(\"---------------------------------------------------\")\n",
        "testing('epoch10_checkpoint_adv.ckpt', True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
